{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RT3IysHWffn"
      },
      "source": [
        "# Building AI Assistants Part I: Build Your Own ChatGPT\n",
        "\n",
        "## Motivation\n",
        "\n",
        "Have you ever watched a sci-fi movie and thought how amazing it would be to have your own friendly AI assistant, like Jarvis in Iron Man? Well, the future is now, because we have all the tools to build these kinds of systems, and that's exactly what we're going to do in this notebook.\n",
        "\n",
        "In just this notebook, you're going to unlock the power to use the OpenAI API, learn insider tips for prompt engineering, and understand how the AI engineering behind ChatGPT works.\n",
        "\n",
        "Let's get started and build our own AI assistant!\n",
        "\n",
        "## A simple start\n",
        "\n",
        "Let's start the conversation by defining a start message that our assistant will read out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "message = \"What can I do to help?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's allow the user to input a response - this is the beginning of defining a loop of back-and-forth conversation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM8wcrzglmp3"
      },
      "source": [
        "Now let's start building up the code that will allow us to have a conversation with our AI assistant. \n",
        "\n",
        "Let's start by getting user input.\n",
        "\n",
        "> Try to look up how to do this yourself. If you get stuck, [here](https://www.google.com/search?q=python+get+user+input) are the search results you should look at."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_input = input(\"Type a prompt...\") # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we need to somehow make a request to an AI system that can interpret the prompt and come up with a response.\n",
        "\n",
        "To use powerful AI systems like GPT4 to provide responses to our messages, we can use the `openai` library (code they have written).\n",
        "\n",
        "We firstly download that from the internet.\n",
        "\n",
        "> Note: code cells starting with `!` run [bash](https://www.gnu.org/software/bash/) (a language used to talk directly to the operating system), rather than running Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we need to import the library into our Python code in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "xNVTrmzFk6pE",
        "outputId": "e4b40193-c507-4642-ee5a-148f0f9283ea"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This Python library contains a bunch of tools that we can use to interact with the OpenAI API.\n",
        "\n",
        "But firstly, let's make sure we're all confident answering the question: What is an API?\n",
        "\n",
        "An API is simply a service running on a computer that understands how to process requests from users and provide relevant responses.\n",
        "\n",
        "For example\n",
        "- The Uber API:\n",
        "    - Request: Get me a ride!\n",
        "    - Response: Ride details\n",
        "    - Many other things\n",
        "- The OpenAI API:\n",
        "    - Request: Your prompt\n",
        "    - Response: GPT4's reply\n",
        "\n",
        "Nowadays every big company has an API (some are publicly accessible, others are used internally)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRkIhx8TlWCU"
      },
      "source": [
        "\n",
        "Because OpenAI needs to track which, and how users are using the API, we need to provide a \"token\" which is essentially like a password.\n",
        "\n",
        "You can find your OpenAI API key [here](https://platform.openai.com/account/api-keys).\n",
        "\n",
        "Note: You will need to ensure you've completed the following steps for our later requests to OpenAI to work.\n",
        "\n",
        "1. Create an OpenAI account\n",
        "2. Set up a payment method\n",
        "\n",
        "Here is the simple setup for using the OpenAI API:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "iLzSohd0le5b",
        "outputId": "eaac69cf-351c-470e-801c-f4bde8a0e6b5"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"YOUR_API_KEY\" # TODO # get the openai library's api_key attribute and set it equal to your api key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have the API set up, let's make our first request.\n",
        "\n",
        "The cell below shows where that fits into our code so far, if we put all of the Python we've written into one cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "message = \"What can I do to help?\"\n",
        "user_input = input(\"Type a prompt...\")\n",
        "# now we need to process that user input to provide a response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make the request to GPT using the OpenAI API, we can read the [documentation](https://platform.openai.com/docs/api-reference) that describes how to do that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"This is a test prompt. What's the response?\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    prompt=prompt,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you run the code above, you should see the AI system's response printed to the console. Congratulations! You have just made your first request to an AI system using the OpenAI API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's put that code into a function, so it's all defined under one name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aagcABjllrTo"
      },
      "outputs": [],
      "source": [
        "def request(prompt):\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        prompt=prompt,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can call this function whenever we want, as shown below. We've encapsulated some much longer and more complicated looking code into a single, short line. This is going to make things super easy for us later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = request(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m63_Apk0l1Cr"
      },
      "source": [
        "Now that we have defined the `request` function, let's test it out with a simple prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "hHcqdo2nmVo1",
        "outputId": "ece8155e-9e0b-4ad8-ad29-38544f078e53"
      },
      "outputs": [],
      "source": [
        "prompt = \"Tell me a story.\"\n",
        "response = request(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVp7M2TXmeII"
      },
      "source": [
        "# Coding the Chat Loop\n",
        "\n",
        "In the previous section, we learned how to make our first request to an AI system and receive a response. However, the conversation was one-way, now, let's turn this into a back and forth conversation by coding the chat loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "while True:\n",
        "    prompt = input(\"Type a prompt...\")\n",
        "    response = request(prompt)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> NOTE: YOU WILL NEED TO INTERRUPT THE NOTEBOOK TO STOP THIS LOOP (there should be a button at the top)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But there's a problem with this. The OpenAI completion model doesn't remember anything about the previous messages. \n",
        "\n",
        "> Contrary to common believe, the system does not learn in real-time, so it is as if you're starting over every time you send a new message.\n",
        "\n",
        "When you send a message to ChatGPT, the entire contents of the conversation are sent to the AI system, so it has all of the context it needs to predict an appropriate response. We will need to do the same thing.\n",
        "\n",
        "## Including the Chat History\n",
        "\n",
        "To enable a continuous conversation, we need to keep track of the chat history. OpenAI's API requires the chat history to be sent as a list of messages, where each message is represented as a dictionary. Check it out in the [docs](https://platform.openai.com/docs/api-reference/chat/create#chat/create-messages). The structure of each message is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": \"hello\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HErGiHZQts2N"
      },
      "source": [
        "- `role` specifies the role of the message author. It can be \"user\", \"assistant\", \"system\", or \"function\".\n",
        "- `content` contains the actual content of the message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = []\n",
        "while True:\n",
        "    prompt = input(\"Type a prompt...\")\n",
        "\n",
        "    message = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt \n",
        "    }\n",
        "    messages.append(message)\n",
        "\n",
        "    response = request(prompt)\n",
        "    print(response)\n",
        "    \n",
        "    message = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": response \n",
        "    }\n",
        "    messages.append(message)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do better than that by putting anything that's duplicated inside a function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_message(messages, new_message, role):\n",
        "    new_message = {\n",
        "        \"role\": role,\n",
        "        \"content\": new_message\n",
        "    }\n",
        "    messages.append(new_message)\n",
        "    return messages\n",
        "\n",
        "messages = []\n",
        "while True:\n",
        "    prompt = input(\"Type a prompt...\")\n",
        "    response = request(prompt)\n",
        "    print(response)\n",
        "    \n",
        "    messages = add_message(messages, prompt)\n",
        "    messages = add_message(messages, response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we should probably put the entire chat into a function too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_message(messages, new_message, role):\n",
        "    new_message = {\n",
        "        \"role\": role,\n",
        "        \"content\": new_message\n",
        "    }\n",
        "    messages.append(new_message)\n",
        "    return messages\n",
        "\n",
        "\n",
        "def chat():\n",
        "    messages = []\n",
        "    while True:\n",
        "        prompt = input(\"Type a prompt...\")\n",
        "        messages = add_message(messages, prompt)\n",
        "\n",
        "        response = request(prompt)\n",
        "        print(response)\n",
        "        messages = add_message(messages, response)\n",
        "\n",
        "\n",
        "chat()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj4ZYURHpIu9"
      },
      "source": [
        "In this chat loop, we start by initializing the chat history with a system message. Then, we continuously prompt the user for input, send that input, and receive the AI assistant's response. We add the assistant's response to the chat history and display it to the user. This loop continues until the user decides to exit by interrupting their Python code.\n",
        "\n",
        "This chat loop allows for a dynamic and interactive conversation with the AI assistant. Feel free to modify the prompts and experiment with different interactions.\n",
        "\n",
        "Now that we have the chat loop implemented, let's move on to the next section to learn about prompt engineering and how to improve the quality of our AI assistant's responses.\n",
        "\n",
        "# Prompt Engineering\n",
        "\n",
        "## What is prompt engineering?\n",
        "\n",
        "Prompt engineering is the process of crafting the prompt given to an AI system in order to shape its responses and improve its performance. It involves carefully selecting the information that is provided to the model, such as the tone, context, personality, and guidelines for behavior. Prompt engineering allows us to guide the AI system towards generating responses that align with our desired outcomes.\n",
        "\n",
        "## System Message\n",
        "\n",
        "To perform prompt engineering, we can start by designing a system message. A system message is the initial message provided to the AI model that sets the stage for the conversation. It frames the context and provides guidelines for the AI's behavior. While it is not part of the actual conversation, it plays a crucial role in shaping the assistant's responses.\n",
        "\n",
        "When designing a system message, consider the following questions:\n",
        "\n",
        "- What tone should the assistant use? Should it be formal, casual, or something else?\n",
        "- What background information should the assistant already know? This can include facts, previous conversations, or any other relevant context.\n",
        "- What personality and style would you like the assistant to have? Should it be friendly, professional, humorous, or something else?\n",
        "- What are your name and the assistant's name? This helps to establish a personal connection.\n",
        "\n",
        "By answering these questions, we can create a system message that provides the necessary framework for the assistant's behavior.\n",
        "\n",
        "### Essential Parts of a System Message\n",
        "\n",
        "A typical system message consists of several essential components:\n",
        "\n",
        "1. * Behavioral Guidelines*: These are recommendations or rules that define how you would like the AI to respond. For example, you might want the AI to avoid certain topics or use specific language.\n",
        "\n",
        "2. * Background Context*: This includes any information that the AI should be aware of before engaging in the conversation. It can include facts, relevant details, or previous interactions.\n",
        "\n",
        "3. * Persona*: The persona represents the personality and style of the AI system. It defines how the assistant speaks, behaves, and interacts with the user. The persona can range from being professional and formal to being more casual and friendly.\n",
        "\n",
        "To get more details about system messages and their implementation, refer to the OpenAI documentation.\n",
        "\n",
        "Here's an example of a system message:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IABTw1LPpMz2"
      },
      "outputs": [],
      "source": [
        "guidelines = \"\"\"\n",
        "Respond with at most two sentences at a time.\n",
        "Stay in character and don't mention that you're an AI because that will break the immersion.\n",
        "\"\"\"\n",
        "\n",
        "system_message = f\"\"\"\n",
        "You are an AI assistant.\n",
        "\n",
        "{guidelines}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNLWdxcpe8y"
      },
      "source": [
        "\n",
        "To ensure that the guidelines are correctly set, let's print them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zsca1sYpnI_",
        "outputId": "2279ec93-4ea2-4b97-afb3-590ea8aef329"
      },
      "outputs": [],
      "source": [
        "print(guidelines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we need to add the guidelines to our chat history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat():\n",
        "    messages = add_message([], system_message, \"system\")\n",
        "    messages = []\n",
        "    while True:\n",
        "        prompt = input(\"Type a prompt...\")\n",
        "        messages = add_message(messages, prompt)\n",
        "\n",
        "        response = request(prompt)\n",
        "        print(response)\n",
        "        messages = add_message(messages, response)\n",
        "\n",
        "\n",
        "chat()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbQD-ip7prQi"
      },
      "source": [
        "\n",
        "## Take-home Challenges\n",
        "\n",
        "1. Add a keyword argument to the `Chat` class to control whether the assistant or the user speaks first. This will allow for more flexibility in the conversation flow.\n",
        "\n",
        "2. Enhance the system message by customizing the behavioral guidelines and persona to align with your desired assistant's behavior.\n",
        "\n",
        "By completing these challenges, you will gain a deeper understanding of prompt engineering and how it can be used to shape the behavior of your AI assistant.\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "Throughout this notebook, we discovered several key insights related to building AI assistants:\n",
        "\n",
        "1. Building AI assistants comes with its own set of challenges, including handling user inputs, generating coherent responses, and maintaining context.\n",
        "\n",
        "2. Making requests to AI systems involves choosing the right model and understanding its limitations and capabilities.\n",
        "\n",
        "3. The chat loop serves as the backbone of our AI assistant, allowing us to engage in dynamic conversations with users.\n",
        "\n",
        "4. Prompt engineering is a powerful technique to influence the behavior of AI models and improve the quality of responses.\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "Now that we have laid the foundation in Part I, it's time to move on to Part II: Building Tools for your AI Assistant. In Part II, we will explore how to define tools that our assistant can use to perform specific tasks. We will also dive into retrieval augmented generation, a technique that combines the benefits of both retrieval-based and generative models.\n",
        "\n",
        "In Part III, we will focus on voice interactions with our assistant. We will learn how to integrate speech recognition and synthesis to enable natural and immersive conversations.\n",
        "\n",
        "By the end of this tutorial series, you will have a comprehensive understanding of building AI assistants and will be equipped with the knowledge and skills to create your own.\n",
        "\n",
        "So let's continue our journey and move on to Part II: Building Tools for your AI Assistant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RqgU6bfpupY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
